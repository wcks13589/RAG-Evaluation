{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597db16-de39-4fcc-b90c-c8992878949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU  langchain langchain_community langchain_nvidia_ai_endpoints langchain_milvus pymupdf ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb195df-d50c-4298-96a7-63fd1d428e61",
   "metadata": {},
   "source": [
    "## 載入Emebedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd2359-34ff-424d-a55c-3358a29cf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "embeddings = NVIDIAEmbeddings(model=\"nemollm-embedding\")\n",
    "\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-zh-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add01a1-d62e-4331-be4a-dcd80de6091d",
   "metadata": {},
   "source": [
    "## 創建Milvus的資料庫\n",
    "若已有則無須創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b868d58-c986-4664-ae16-c263b2469803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "\n",
    "# from langchain_community.vectorstores import Milvus\n",
    "\n",
    "# The easiest way is to use Milvus Lite where everything is stored in a local file.\n",
    "# If you have a Milvus server you can use the server URI such as \"http://localhost:19530\".\n",
    "# URI = \"./milvus_example.db\"\n",
    "URI = \"http://localhost:19530\"\n",
    "\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"uri\": URI},\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n",
    "    auto_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052a472-325b-4907-818d-d5bf667fc613",
   "metadata": {},
   "source": [
    "## 定義Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f17c17-872d-43d4-866e-f39216b4ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "EMBEDDING_MODEL = \"BAAI/bge-large-zh-v1.5\"\n",
    "CHUNK_SIZE = 100\n",
    "CHUNK_OVERLAP = 20\n",
    "\n",
    "\n",
    "def get_text_splitter(\n",
    "    embedding_model_name=\"BAAI/bge-large-zh-v1.5\", chunk_size=506, chunk_overlap=200\n",
    ") -> SentenceTransformersTokenTextSplitter:\n",
    "    \"\"\"Return the token text splitter instance from langchain.\n",
    "\n",
    "    Returns:\n",
    "        SentenceTransformersTokenTextSplitter: Splitting text to tokens using sentence model tokenizer\n",
    "    \"\"\"\n",
    "    # Chunksize and chunk overlap can up updated using APP_TEXTSPLITTER_CHUNKSIZE and APP_TEXTSPLITTER_CHUNKOVERLAP respectively\n",
    "    return SentenceTransformersTokenTextSplitter(\n",
    "        model_name=embedding_model_name,\n",
    "        tokens_per_chunk=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "text_splitter = get_text_splitter(EMBEDDING_MODEL, CHUNK_SIZE, CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8e7cb-8e11-4215-aba4-e17ea67d1eca",
   "metadata": {},
   "source": [
    "## 資料存取一: PDF\n",
    "### 讀取資料夾內所有的PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8e175-8aca-4ee3-a0da-608a46fa82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "def find_pdfs(folder_path):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                pdf_files.append(full_path)\n",
    "    return pdf_files\n",
    "\n",
    "folder_path = \"/workspace/pdf/\"\n",
    "\n",
    "pdf_paths = find_pdfs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882cd00-635f-47a0-9a9a-287e862005cf",
   "metadata": {},
   "source": [
    "### 分割PDF的內容後，存入Milvus資料庫中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60718a-4fc4-4f44-93bb-993a2a981e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_path in pdf_paths:\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "    vector_store.add_documents(documents=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84ff5a-c089-47a6-a953-3bbfeab0011c",
   "metadata": {},
   "source": [
    "## 資料存取二: 純文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74164ab-83c5-48aa-9f8d-60b99c747d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "今天天氣真好\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2da9ba-d47c-426c-a72a-d10ac3356259",
   "metadata": {},
   "source": [
    "### 分割純文字的內容後，存入Milvus資料庫中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985c54d-f29f-42cf-9a70-29382e490260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents([text], metadatas=[{'source': '', 'file_path': '', 'page': 0, 'total_pages': 0, 'format': '', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': '', 'creationDate': '', 'modDate': '', 'trapped': ''}])\n",
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38892b3a-bb80-4dc4-9990-a026dce320f3",
   "metadata": {},
   "source": [
    "## 查詢Milvus資料庫內有多少個Chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db715d5a-0777-4254-b188-43f5732014fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, connections\n",
    "\n",
    "# 連接到 Milvus\n",
    "connections.connect(uri=URI)\n",
    "# connections.connect(\"LangChainCollection\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "collection_name = vector_store.collection_name\n",
    "collection = Collection(collection_name)\n",
    "\n",
    "# 查詢資料總數\n",
    "print(f\"Collection '{collection.name}' has {collection.num_entities} entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ee3d4-2b8b-449b-bbed-21900bffaa92",
   "metadata": {},
   "source": [
    "## 刪除Milvus資料庫的內文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4477790-14ab-4f57-a902-9aa0f1e2a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete All Files\n",
    "vector_store.delete(expr=f\"pk >= 0\")\n",
    "\n",
    "# By metadata\n",
    "# filename = \"tweet\"\n",
    "# vector_store.delete(expr=f\"source == '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4542bcd-f9e5-4219-a44f-84d539416729",
   "metadata": {},
   "source": [
    "## 搜尋資料庫中的文件\n",
    "### 方法一: vector_store.similarity_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acaf3e5-3ac5-4120-a667-e084248954a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=K,\n",
    ")\n",
    "\n",
    "# results = vector_store.similarity_search(\n",
    "#     \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "#     k=K,\n",
    "#     expr='source == \"tweet\"',\n",
    "# )\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749bcd4-4de7-486b-8cd7-be13af84d4f3",
   "metadata": {},
   "source": [
    "### 方法二: retriever.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f1ff1-0ea9-4415-a110-b6d26bccd8fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\": K}\n",
    ")\n",
    "\n",
    "# retriever = vector_store.as_retriever(\n",
    "#     search_kwargs={\"k\": K, \"expr\": 'source == \"tweet\"'}\n",
    "# )\n",
    "\n",
    "retrieved_docs = retriever.invoke(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\"\n",
    ")\n",
    "\n",
    "for res in retrieved_docs:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fa858-c82c-4079-a45b-4c33a9f7df45",
   "metadata": {},
   "source": [
    "## 建立RAG的流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d3bc9-e4d0-42d7-8c94-c3fea7a94e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "\n",
    "llm = ChatNVIDIA(\n",
    "    base_url=\"http://0.0.0.0:8000/v1\",\n",
    "    model=\"meta/llama3-8b-instruct\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.0,\n",
    ")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c938e-4cbf-417e-937f-48dc373ffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b6fb9-722b-473a-a9cd-5e5668054866",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"請問探針卡是哪個處室管理的?\"\n",
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416b1e4-871d-4a35-9e6a-df13cb1b2741",
   "metadata": {},
   "source": [
    "## 評估RAG準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e204cf-99fa-49a3-91fb-aab291ad13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備欲驗證的問題\n",
    "sample_queries = [\n",
    "    \"Who introduced the theory of relativity?\",\n",
    "    \"Who was the first computer programmer?\",\n",
    "    \"What did Isaac Newton contribute to science?\",\n",
    "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
    "    \"What is the theory of evolution by natural selection?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd12e3-0cfa-41d9-96d2-3f8ba06d8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for query in sample_queries:\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    response = rag_chain.invoke(query)\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": query,\n",
    "            \"retrieved_contexts\": [page.page_content for page in relevant_docs],\n",
    "            \"response\": response,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc08b6-224a-4fc4-8657-444924e0116c",
   "metadata": {},
   "source": [
    "## 使用RAGAS來協助評估RAG的準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029f40a9-e41c-4543-bc07-fef6b5ef6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7602d02-bc32-46e1-a62e-fbb7dff0de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embeddings = retriever.vectorstore.embeddings\n",
    "from ragas.metrics import AnswerRelevancy, Faithfulness, ContextUtilization \n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,\n",
    "                  metrics=[AnswerRelevancy(), ContextUtilization()],\n",
    "                  llm=evaluator_llm,\n",
    "                  embeddings=evaluator_embeddings\n",
    "                 )\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
